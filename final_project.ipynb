{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7BOqG2HAqhD"
      },
      "source": [
        "# Using Satellite Imagery and Machine Learning for Urban Heat Risk Analysis in San Francisco\n",
        "\n",
        "> Background\n",
        "\n",
        "    Urban heat risk is a growing concern in many cities around the world, including San Francisco. The rapid urbanization and industrialization of San Francisco. have led to the emergence of urban heat islands, characterized by higher temperatures in densely built-up areas compared to surrounding suburban areas. This phenomenon poses significant health risks to residents, especially during heat waves, and can exacerbate existing socioeconomic inequalities.\n",
        "\n",
        "> Problem Statement\n",
        "\n",
        "    The main objective of this project is to assess the urban heat risk in San Francisco. over the past 5 years using satellite imagery and machine learning. The analysis will identify areas with high heat risk and help city planners and policymakers implement targeted interventions to reduce heat exposure, particularly for vulnerable populations.\n",
        "\n",
        "> Dataset\n",
        "\n",
        "    For this project, I will use publicly available Landsat 8 satellite imagery through the Google Earth Engine of San Francisco in 2020. The Landsat 8 images provide high-resolution (30-meter) data in multiple spectral bands, including the thermal infrared band, which is essential for calculating land surface temperature. Then I use Python script that utilizes the Google Earth Engine (GEE) Python API to download Landsat 8 satellite imagery for the year 2020 over San Francisco with less than 5% cloud cover. The script loops through each image in the resulting image collection, exports them as GeoTIFF files, and uploads them to a Google Cloud Storage bucket named ‘sf_imagery’. Moreover, GeoTIFF images can be extracted from the specified Google Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install earthengine-api\n",
        "!pip install rasterio scikit-image\n",
        "!pip install lightgbm xgboost\n",
        "!pip install us\n",
        "!pip install census\n",
        "!pip install folium\n",
        "!pip install rasterio\n",
        "!pip install geemap\n",
        "!pip install states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4ge2IEtKaPl",
        "outputId": "29924f2c-b3b7-4806-86e0-d247539ec1b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.12/dist-packages (1.5.24)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (3.6.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (0.2.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (0.31.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (2.32.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (4.2.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1dev,>=0.9.2->earthengine-api) (3.2.5)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api) (2025.11.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.6.1)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Collecting us\n",
            "  Using cached us-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jellyfish (from us)\n",
            "  Using cached jellyfish-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (642 bytes)\n",
            "Using cached us-3.2.0-py3-none-any.whl (13 kB)\n",
            "Using cached jellyfish-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n",
            "Installing collected packages: jellyfish, us\n",
            "Successfully installed jellyfish-1.2.1 us-3.2.0\n",
            "Requirement already satisfied: census in /usr/local/lib/python3.12/dist-packages (0.8.24)\n",
            "Requirement already satisfied: requests>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from census) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (2025.11.12)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.12/dist-packages (0.20.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from folium) (0.8.2)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from folium) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from folium) (2.32.4)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.12/dist-packages (from folium) (2025.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9->folium) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (2025.11.12)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
            "Requirement already satisfied: geemap in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: bqplot in /usr/local/lib/python3.12/dist-packages (from geemap) (0.12.45)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.12/dist-packages (from geemap) (0.1.5)\n",
            "Requirement already satisfied: earthengine-api>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from geemap) (1.5.24)\n",
            "Requirement already satisfied: eerepr>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from geemap) (0.1.2)\n",
            "Requirement already satisfied: folium>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from geemap) (0.20.0)\n",
            "Requirement already satisfied: geocoder in /usr/local/lib/python3.12/dist-packages (from geemap) (1.38.1)\n",
            "Requirement already satisfied: ipyevents in /usr/local/lib/python3.12/dist-packages (from geemap) (2.0.4)\n",
            "Requirement already satisfied: ipyfilechooser>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from geemap) (0.6.0)\n",
            "Requirement already satisfied: ipyleaflet>=0.19.2 in /usr/local/lib/python3.12/dist-packages (from geemap) (0.20.0)\n",
            "Requirement already satisfied: ipytree in /usr/local/lib/python3.12/dist-packages (from geemap) (0.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from geemap) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from geemap) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from geemap) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from geemap) (5.24.1)\n",
            "Requirement already satisfied: pyperclip in /usr/local/lib/python3.12/dist-packages (from geemap) (1.11.0)\n",
            "Requirement already satisfied: pyshp>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from geemap) (3.0.2.post1)\n",
            "Requirement already satisfied: python-box in /usr/local/lib/python3.12/dist-packages (from geemap) (7.3.2)\n",
            "Requirement already satisfied: scooby in /usr/local/lib/python3.12/dist-packages (from geemap) (0.11.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from earthengine-api>=1.0.0->geemap) (3.6.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.12/dist-packages (from earthengine-api>=1.0.0->geemap) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from earthengine-api>=1.0.0->geemap) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from earthengine-api>=1.0.0->geemap) (0.2.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from earthengine-api>=1.0.0->geemap) (0.31.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from earthengine-api>=1.0.0->geemap) (2.32.4)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from folium>=0.17.0->geemap) (0.8.2)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from folium>=0.17.0->geemap) (3.1.6)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.12/dist-packages (from folium>=0.17.0->geemap) (2025.10.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from ipyfilechooser>=0.6.0->geemap) (7.7.1)\n",
            "Requirement already satisfied: jupyter-leaflet<0.21,>=0.20 in /usr/local/lib/python3.12/dist-packages (from ipyleaflet>=0.19.2->geemap) (0.20.0)\n",
            "Requirement already satisfied: traittypes<3,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from ipyleaflet>=0.19.2->geemap) (0.2.3)\n",
            "Requirement already satisfied: traitlets>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from bqplot->geemap) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->geemap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->geemap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->geemap) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from geocoder->geemap) (8.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from geocoder->geemap) (1.0.0)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.12/dist-packages (from geocoder->geemap) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from geocoder->geemap) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->geemap) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->geemap) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->geemap) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->geemap) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->geemap) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->geemap) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->geemap) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->geemap) (9.1.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.1->earthengine-api>=1.0.0->geemap) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.1->earthengine-api>=1.0.0->geemap) (4.2.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api>=1.0.0->geemap) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api>=1.0.0->geemap) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api>=1.0.0->geemap) (4.9.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9->folium>=0.17.0->geemap) (3.0.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api>=1.0.0->geemap) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api>=1.0.0->geemap) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api>=1.0.0->geemap) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api>=1.0.0->geemap) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api>=1.0.0->geemap) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api>=1.0.0->geemap) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->earthengine-api>=1.0.0->geemap) (2025.11.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ratelim->geocoder->geemap) (4.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api>=1.0.0->geemap) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api>=1.0.0->geemap) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api>=1.0.0->geemap) (1.26.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.9.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api>=1.0.0->geemap) (0.6.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (5.9.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.14)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.25.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.29.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.4.0)\n",
            "Requirement already satisfied: states in /usr/local/lib/python3.12/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import zipfile\n",
        "import rasterio\n",
        "from io import BytesIO\n",
        "from scipy import stats, ndimage\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError, IoU, Precision, Recall\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Image processing\n",
        "from skimage.transform import resize\n",
        "from skimage.filters import sobel\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.measure import regionprops\n",
        "\n",
        "# Census data\n",
        "import census\n",
        "from us import states\n"
      ],
      "metadata": {
        "id": "vOTWvMTQKJIU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Import"
      ],
      "metadata": {
        "id": "zbNmpTQkX-Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='sfurbanheatisland')"
      ],
      "metadata": {
        "id": "fSPT8BjCMQrn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nConfiguration:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"./dl_output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "# NYC boundaries\n",
        "NYC_BOUNDS = [-74.3, 40.5, -73.65, 40.95]\n",
        "print(f\"Study area: New York City\")\n",
        "print(f\"Bounds: {NYC_BOUNDS}\")\n",
        "\n",
        "# Analysis parameters\n",
        "START_DATE = '2025-06-01'\n",
        "END_DATE = '2025-10-31'\n",
        "CLOUD_MAX = 10\n",
        "\n",
        "# Deep Learning parameters\n",
        "PATCH_SIZE = 64  # Size of image patches\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "SAMPLE_SIZE = 5000  # Number of patches to use\n",
        "\n",
        "print(f\"\\nDeep Learning Parameters:\")\n",
        "print(f\"  Patch size: {PATCH_SIZE}x{PATCH_SIZE}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")"
      ],
      "metadata": {
        "id": "s6Flp0xkK0nG",
        "outputId": "db4563e5-d7ed-4093-b2fd-826efbdc8db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration:\n",
            "--------------------------------------------------\n",
            "Output directory: ./dl_output\n",
            "Study area: New York City\n",
            "Bounds: [-74.3, 40.5, -73.65, 40.95]\n",
            "\n",
            "Deep Learning Parameters:\n",
            "  Patch size: 64x64\n",
            "  Batch size: 16\n",
            "  Epochs: 50\n",
            "  Learning rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLFZiKnnAqhF"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this section, it generates a set of satellite-derived vegetation indices including Normalized Difference Vegetation Index (NDVI), Normalized Difference Built-Up Index (NDBI), Normalized Difference Water Index (NDWI), Built-Up Index (BU), Enhanced Vegetation Index (EVI), and Soil-Adjusted Vegetation Index (SAVI) for a region of interest in San Francisco.\n",
        "\n",
        "The code first defines the region of San Francisco and filters the Landsat-8 image collection to get the image on September 30th, 2022, with less than 20% cloud cover. It then calculates the median of the filtered image collection and computes the vegetation indices using the normalized difference or expression methods. The vegetation indices are clipped to the region of interest, and then added to a Folium map, along with the San Francisco neighborhood boundaries as a GeoJSON layer. The final output is an interactive map that displays the vegetation indices for the selected area."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. DATA COLLECTION"
      ],
      "metadata": {
        "id": "HVH6lncimXcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 1: DOWNLOAD SATELLITE DATA\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "print(\"1.1 Creating Earth Engine region...\")\n",
        "region = ee.Geometry.Rectangle(NYC_BOUNDS)\n",
        "print(f\"    ✓ Region created\")\n",
        "\n",
        "print(\"\\n1.2 Searching for Landsat imagery...\")\n",
        "print(f\"    Date range: {START_DATE} to {END_DATE}\")\n",
        "print(f\"    Max cloud cover: {CLOUD_MAX}%\")\n",
        "\n",
        "# Get Landsat collection\n",
        "landsat = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2') \\\n",
        "    .merge(ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')) \\\n",
        "    .filterBounds(region) \\\n",
        "    .filterDate(START_DATE, END_DATE) \\\n",
        "    .filter(ee.Filter.lt('CLOUD_COVER', CLOUD_MAX))\n",
        "\n",
        "# Get median composite\n",
        "composite = landsat.median()\n",
        "\n",
        "# Get image info\n",
        "count = landsat.size().getInfo()\n",
        "print(f\"    ✓ Found {count} images\")\n",
        "print(f\"    ✓ Creating median composite\")\n",
        "\n",
        "print(\"\\n1.3 Calculating spectral indices in Earth Engine...\")\n",
        "\n",
        "# Scale bands\n",
        "b2 = composite.select('SR_B2').multiply(0.0000275).add(-0.2)  # Blue\n",
        "b3 = composite.select('SR_B3').multiply(0.0000275).add(-0.2)  # Green\n",
        "b4 = composite.select('SR_B4').multiply(0.0000275).add(-0.2)  # Red\n",
        "b5 = composite.select('SR_B5').multiply(0.0000275).add(-0.2)  # NIR\n",
        "b6 = composite.select('SR_B6').multiply(0.0000275).add(-0.2)  # SWIR1\n",
        "b7 = composite.select('SR_B7').multiply(0.0000275).add(-0.2)  # SWIR2\n",
        "thermal = composite.select('ST_B10').multiply(0.00341802).add(149.0)  # Thermal in Kelvin\n",
        "\n",
        "# Calculate indices\n",
        "ndvi = b5.subtract(b4).divide(b5.add(b4)).rename('NDVI')\n",
        "ndbi = b6.subtract(b5).divide(b6.add(b5)).rename('NDBI')\n",
        "ndwi = b5.subtract(b6).divide(b5.add(b6)).rename('NDWI')\n",
        "mndwi = b3.subtract(b6).divide(b3.add(b6)).rename('MNDWI')\n",
        "bu = ndbi.subtract(ndvi).rename('BU')\n",
        "lst_celsius = thermal.subtract(273.15).rename('LST')\n",
        "\n",
        "# Combine all bands\n",
        "final_image = b2.addBands([b3, b4, b5, b6, b7, ndvi, ndbi, ndwi, mndwi, bu, lst_celsius])\n",
        "band_names = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2',\n",
        "              'NDVI', 'NDBI', 'NDWI', 'MNDWI', 'BU', 'LST']\n",
        "final_image = final_image.rename(band_names)\n",
        "\n",
        "print(f\"    ✓ Calculated {len(band_names)} bands/indices\")\n",
        "print(f\"    Bands: {', '.join(band_names)}\")\n",
        "\n",
        "print(\"\\n1.4 Downloading image from Earth Engine...\")\n",
        "print(\"    This may take 1-2 minutes...\")\n",
        "\n",
        "# Download at reduced resolution for speed\n",
        "scale = 90  # 90m resolution\n",
        "download_url = final_image.getDownloadURL({\n",
        "    'region': region.coordinates().getInfo(),\n",
        "    'scale': scale,\n",
        "    'format': 'GEO_TIFF'\n",
        "})\n",
        "\n",
        "response = requests.get(download_url)\n",
        "\n",
        "# Check if it's a redirect\n",
        "try:\n",
        "    json_response = response.json()\n",
        "    if 'downloadUrl' in json_response:\n",
        "        print(\"    Following redirect...\")\n",
        "        response = requests.get(json_response['downloadUrl'])\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print(f\"    ✓ Downloaded {len(response.content) / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "print(\"\\n1.5 Processing downloaded image...\")\n",
        "\n",
        "# Read the image\n",
        "if not response.content[:4] == b'PK\\x03\\x04':\n",
        "    # Single GeoTIFF\n",
        "    print(\"    Processing as GeoTIFF...\")\n",
        "    with rasterio.open(BytesIO(response.content)) as src:\n",
        "        img_array = np.stack([src.read(i+1) for i in range(src.count)])\n",
        "else:\n",
        "    # ZIP file with multiple TIFFs\n",
        "    print(\"    Processing as ZIP file...\")\n",
        "    arrays = []\n",
        "    with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
        "        tiff_files = sorted([f for f in z.namelist() if f.endswith('.tif')])\n",
        "        print(f\"    Found {len(tiff_files)} TIFF files\")\n",
        "\n",
        "        for tiff_file in tiff_files:\n",
        "            with z.open(tiff_file) as f:\n",
        "                with rasterio.open(BytesIO(f.read())) as src:\n",
        "                    arrays.append(src.read(1))\n",
        "\n",
        "    img_array = np.stack(arrays)\n",
        "\n",
        "print(f\"    ✓ Image shape: {img_array.shape}\")\n",
        "print(f\"      Bands: {img_array.shape[0]}\")\n",
        "print(f\"      Height: {img_array.shape[1]}\")\n",
        "print(f\"      Width: {img_array.shape[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-R23bYMmVNU",
        "outputId": "41b22caa-e425-4ef0-94b9-ab3ffcf3ffb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 1: DOWNLOAD SATELLITE DATA\n",
            "================================================================================\n",
            "\n",
            "1.1 Creating Earth Engine region...\n",
            "    ✓ Region created\n",
            "\n",
            "1.2 Searching for Landsat imagery...\n",
            "    Date range: 2025-06-01 to 2025-10-31\n",
            "    Max cloud cover: 10%\n",
            "    ✓ Found 18 images\n",
            "    ✓ Creating median composite\n",
            "\n",
            "1.3 Calculating spectral indices in Earth Engine...\n",
            "    ✓ Calculated 12 bands/indices\n",
            "    Bands: Blue, Green, Red, NIR, SWIR1, SWIR2, NDVI, NDBI, NDWI, MNDWI, BU, LST\n",
            "\n",
            "1.4 Downloading image from Earth Engine...\n",
            "    This may take 1-2 minutes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Trainin Patches"
      ],
      "metadata": {
        "id": "spDbmhPsm2Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 2: CREATE TRAINING PATCHES\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "print(\"2.1 Preprocessing image data...\")\n",
        "\n",
        "# Handle invalid values\n",
        "img_array = img_array.astype(np.float32)\n",
        "img_array[img_array == 0] = np.nan\n",
        "\n",
        "# Check temperature range\n",
        "lst_channel = img_array[-1]  # Last channel is LST\n",
        "print(f\"    Temperature range: {np.nanmin(lst_channel):.1f}°C to {np.nanmax(lst_channel):.1f}°C\")\n",
        "\n",
        "print(\"\\n2.2 Creating patches for deep learning...\")\n",
        "print(f\"    Patch size: {PATCH_SIZE}x{PATCH_SIZE}\")\n",
        "print(f\"    Stride: {PATCH_SIZE // 2} (50% overlap)\")\n",
        "\n",
        "patches = []\n",
        "patch_temps = []\n",
        "\n",
        "n_channels, height, width = img_array.shape\n",
        "\n",
        "# Create overlapping patches\n",
        "for i in range(0, height - PATCH_SIZE, PATCH_SIZE // 2):\n",
        "    for j in range(0, width - PATCH_SIZE, PATCH_SIZE // 2):\n",
        "        # Extract patch\n",
        "        patch = img_array[:, i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n",
        "\n",
        "        # Check if patch has valid data (less than 10% NaN)\n",
        "        nan_ratio = np.sum(np.isnan(patch)) / patch.size\n",
        "\n",
        "        if nan_ratio < 0.1:\n",
        "            # Fill remaining NaNs with mean\n",
        "            for c in range(n_channels):\n",
        "                channel_mean = np.nanmean(patch[c])\n",
        "                patch[c] = np.nan_to_num(patch[c], nan=channel_mean)\n",
        "\n",
        "            # Transpose to (H, W, C) for TensorFlow\n",
        "            patch = np.transpose(patch, (1, 2, 0))\n",
        "\n",
        "            # Get average temperature for this patch\n",
        "            avg_temp = np.mean(patch[:, :, -1])  # LST is last channel\n",
        "\n",
        "            patches.append(patch)\n",
        "            patch_temps.append(avg_temp)\n",
        "\n",
        "patches = np.array(patches)\n",
        "patch_temps = np.array(patch_temps)\n",
        "\n",
        "print(f\"    ✓ Created {len(patches)} valid patches\")\n",
        "print(f\"    ✓ Patch array shape: {patches.shape}\")\n",
        "\n",
        "# Subsample if too many patches\n",
        "if len(patches) > SAMPLE_SIZE:\n",
        "    print(f\"\\n2.3 Subsampling to {SAMPLE_SIZE} patches...\")\n",
        "    idx = np.random.choice(len(patches), SAMPLE_SIZE, replace=False)\n",
        "    patches = patches[idx]\n",
        "    patch_temps = patch_temps[idx]\n",
        "    print(f\"    ✓ Subsampled to {len(patches)} patches\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiDimOwuaLJR",
        "outputId": "4c767e38-2389-4630-ca83-f3b5b6c1628c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 2: PREPROCESSING\n",
            "================================================================================\n",
            "\n",
            "2.1 Applying Landsat scaling...\n",
            "    Training LST range: 17.6°C to 65.5°C\n",
            "    Prediction LST range: 11.1°C to 56.7°C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: FEATURE ENGINEERING"
      ],
      "metadata": {
        "id": "Yla3zH6im7LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 3: PREPARE DATA FOR DEEP LEARNING\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "print(\"3.1 Extracting features and labels...\")\n",
        "\n",
        "# Features: all bands except LST\n",
        "X = patches[:, :, :, :-1]  # All channels except last (LST)\n",
        "print(f\"    Features shape: {X.shape}\")\n",
        "print(f\"    Feature channels: {X.shape[-1]} (all bands except LST)\")\n",
        "\n",
        "# Labels for regression: average temperature per patch\n",
        "y_regression = patch_temps\n",
        "print(f\"    Regression labels shape: {y_regression.shape}\")\n",
        "print(f\"    Temperature range: {y_regression.min():.1f}°C to {y_regression.max():.1f}°C\")\n",
        "\n",
        "print(\"\\n3.2 Creating segmentation labels...\")\n",
        "\n",
        "# Create heat risk categories based on temperature\n",
        "temp_percentiles = np.percentile(y_regression, [33, 67])\n",
        "print(f\"    Temperature percentiles:\")\n",
        "print(f\"      33rd: {temp_percentiles[0]:.1f}°C\")\n",
        "print(f\"      67th: {temp_percentiles[1]:.1f}°C\")\n",
        "\n",
        "# Create segmentation masks (3 classes: low, medium, high)\n",
        "y_segmentation = np.zeros((len(patches), PATCH_SIZE, PATCH_SIZE, 3))\n",
        "\n",
        "for i, patch in enumerate(patches):\n",
        "    temp_map = patch[:, :, -1]  # Temperature map for this patch\n",
        "\n",
        "    # Low risk (cool)\n",
        "    y_segmentation[i, :, :, 0] = (temp_map < temp_percentiles[0]).astype(float)\n",
        "\n",
        "    # Medium risk\n",
        "    y_segmentation[i, :, :, 1] = ((temp_map >= temp_percentiles[0]) &\n",
        "                                   (temp_map < temp_percentiles[1])).astype(float)\n",
        "\n",
        "    # High risk (hot)\n",
        "    y_segmentation[i, :, :, 2] = (temp_map >= temp_percentiles[1]).astype(float)\n",
        "\n",
        "print(f\"    ✓ Created segmentation masks\")\n",
        "print(f\"    Segmentation shape: {y_segmentation.shape}\")\n",
        "\n",
        "print(\"\\n3.3 Normalizing features...\")\n",
        "\n",
        "# Normalize each channel\n",
        "for c in range(X.shape[-1]):\n",
        "    channel_mean = np.mean(X[:, :, :, c])\n",
        "    channel_std = np.std(X[:, :, :, c])\n",
        "    X[:, :, :, c] = (X[:, :, :, c] - channel_mean) / (channel_std + 1e-8)\n",
        "    print(f\"    Channel {c}: normalized (mean=0, std=1)\")\n",
        "\n",
        "print(\"\\n3.4 Splitting data into train/test sets...\")\n",
        "\n",
        "X_train, X_test, y_reg_train, y_reg_test, y_seg_train, y_seg_test = train_test_split(\n",
        "    X, y_regression, y_segmentation,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"    ✓ Training set: {X_train.shape[0]} patches\")\n",
        "print(f\"    ✓ Test set: {X_test.shape[0]} patches\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIIWYIIoMlaG",
        "outputId": "a88b7795-8161-4859-a24d-1010c13dcf58"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 3: FEATURE ENGINEERING\n",
            "================================================================================\n",
            "\n",
            "3.1 Calculating indices...\n",
            "    ✓ Calculated 9 indices for both years\n",
            "\n",
            "3.2 Creating feature matrices...\n",
            "    Training samples: 30,000\n",
            "    Prediction samples: 30,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: TEMPORAL PREDICTION MODEL"
      ],
      "metadata": {
        "id": "CqJdPLfxYh4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 4: TEMPORAL PREDICTION MODEL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n4.1 Training models on 2024 data...\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_predict_scaled = scaler.transform(X_predict)\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=20,\n",
        "        random_state=RANDOM_SEED,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=RANDOM_SEED\n",
        "    )\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n    Training {name}...\")\n",
        "\n",
        "    # Train on 2024\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on 2025 (2023 proxy)\n",
        "    y_pred = model.predict(X_predict)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_predict, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_predict, y_pred))\n",
        "    r2 = r2_score(y_predict, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'predictions': y_pred,\n",
        "        'mae': mae,\n",
        "        'rmse': rmse,\n",
        "        'r2': r2\n",
        "    }\n",
        "\n",
        "    print(f\"      Temporal MAE: {mae:.2f}°C\")\n",
        "    print(f\"      Temporal RMSE: {rmse:.2f}°C\")\n",
        "    print(f\"      Temporal R²: {r2:.3f}\")\n",
        "\n",
        "# Select best model\n",
        "best_model_name = max(results, key=lambda x: results[x]['r2'])\n",
        "best_model = results[best_model_name]['model']\n",
        "print(f\"\\n    🏆 Best temporal model: {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZIUmfEhRKbi",
        "outputId": "faa4764d-f8f5-4215-b025-0cdfecf30e2b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 4: TEMPORAL PREDICTION MODEL\n",
            "================================================================================\n",
            "\n",
            "4.1 Training models on 2024 data...\n",
            "\n",
            "    Training Random Forest...\n",
            "      Temporal MAE: 2.21°C\n",
            "      Temporal RMSE: 2.93°C\n",
            "      Temporal R²: 0.839\n",
            "\n",
            "    Training Gradient Boosting...\n",
            "      Temporal MAE: 2.19°C\n",
            "      Temporal RMSE: 2.91°C\n",
            "      Temporal R²: 0.841\n",
            "\n",
            "    🏆 Best temporal model: Gradient Boosting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5: HIGH-RISK AREA IDENTIFICATION"
      ],
      "metadata": {
        "id": "niU8YkfSnqAX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O23gr5tAqhF",
        "outputId": "bd0e0746-a172-4908-9728-1bd6ff226a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 5: HIGH-RISK AREA IDENTIFICATION\n",
            "================================================================================\n",
            "\n",
            "5.1 Identifying high-temperature areas...\n",
            "    High-risk threshold: 42.7°C (top 20%)\n",
            "    High-risk pixels: 69,474 (20.0%)\n",
            "\n",
            "5.2 Clustering high-risk areas...\n",
            "    ✓ Identified 5 high-risk clusters\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 5: HIGH-RISK AREA IDENTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n5.1 Identifying high-temperature areas...\")\n",
        "\n",
        "# Get full predictions\n",
        "y_pred_full = best_model.predict(X_predict_full)\n",
        "\n",
        "# Define high-risk threshold\n",
        "threshold = np.percentile(y_pred_full, HIGH_RISK_PERCENTILE)\n",
        "high_risk_mask = y_pred_full > threshold\n",
        "\n",
        "print(f\"    High-risk threshold: {threshold:.1f}°C (top {100-HIGH_RISK_PERCENTILE}%)\")\n",
        "print(f\"    High-risk pixels: {high_risk_mask.sum():,} ({high_risk_mask.mean()*100:.1f}%)\")\n",
        "\n",
        "# Create spatial high-risk map\n",
        "height, width = predict_img.shape[1], predict_img.shape[2]\n",
        "risk_map = np.zeros(height * width)\n",
        "valid_idx = ~np.isnan(X_predict_full).any(axis=1) & ~np.isinf(X_predict_full).any(axis=1)\n",
        "risk_map[valid_idx] = y_pred_full\n",
        "risk_map = risk_map.reshape(height, width)\n",
        "\n",
        "# Identify clusters\n",
        "print(\"\\n5.2 Clustering high-risk areas...\")\n",
        "\n",
        "high_risk_coords = np.column_stack(np.where(risk_map > threshold))\n",
        "if len(high_risk_coords) > 100:\n",
        "    # Subsample for clustering\n",
        "    sample_coords = high_risk_coords[\n",
        "        np.random.choice(len(high_risk_coords), 100, replace=False)\n",
        "    ]\n",
        "else:\n",
        "    sample_coords = high_risk_coords\n",
        "\n",
        "# K-means clustering\n",
        "n_clusters = min(5, len(sample_coords) // 20)\n",
        "if n_clusters > 0:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_SEED)\n",
        "    clusters = kmeans.fit_predict(sample_coords)\n",
        "    print(f\"    ✓ Identified {n_clusters} high-risk clusters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6: DEMOGRAPHIC ANALYSIS\n"
      ],
      "metadata": {
        "id": "AMl1TCMHs0HZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nio4JGVAqhF",
        "outputId": "f4e1e6da-b38c-4ccb-8cbb-7daced397094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 6: DEMOGRAPHIC ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "    Loading demographic data...\n",
            "      ✓ Loaded 200 census tracts\n",
            "\n",
            "6.1 Analyzing correlation with vulnerability...\n",
            "    Correlation (temperature vs vulnerability): -0.006\n",
            "    P-value: 0.9381\n",
            "    ⚠ Relationship not statistically significant\n",
            "\n",
            "6.2 Identifying vulnerable hot spots...\n",
            "    Vulnerable areas mean temperature: 35.4°C\n",
            "    Overall mean temperature: 35.5°C\n",
            "    Temperature difference: -0.2°C\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 6: DEMOGRAPHIC ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load demographic data\n",
        "demographic_data = get_demographic_data()\n",
        "\n",
        "print(\"\\n6.1 Analyzing correlation with vulnerability...\")\n",
        "\n",
        "# For each census tract, get average predicted temperature\n",
        "tract_temperatures = []\n",
        "tract_vulnerabilities = []\n",
        "\n",
        "for _, tract in demographic_data.iterrows():\n",
        "    # Find nearest pixel to tract centroid\n",
        "    # (Simplified - in real analysis, use proper spatial join)\n",
        "    lon_idx = int((tract['lon'] - NYC_BOUNDS['west']) /\n",
        "                  (NYC_BOUNDS['east'] - NYC_BOUNDS['west']) * width)\n",
        "    lat_idx = int((NYC_BOUNDS['north'] - tract['lat']) /\n",
        "                  (NYC_BOUNDS['north'] - NYC_BOUNDS['south']) * height)\n",
        "\n",
        "    if 0 <= lon_idx < width and 0 <= lat_idx < height:\n",
        "        temp = risk_map[lat_idx, lon_idx]\n",
        "        if not np.isnan(temp) and temp > 0:\n",
        "            tract_temperatures.append(temp)\n",
        "            tract_vulnerabilities.append(tract['vulnerability_index'])\n",
        "\n",
        "# Calculate correlation\n",
        "if len(tract_temperatures) > 10:\n",
        "    correlation, p_value = stats.pearsonr(tract_temperatures, tract_vulnerabilities)\n",
        "    print(f\"    Correlation (temperature vs vulnerability): {correlation:.3f}\")\n",
        "    print(f\"    P-value: {p_value:.4f}\")\n",
        "\n",
        "    if p_value < 0.05:\n",
        "        print(\"    ✓ Statistically significant relationship found!\")\n",
        "    else:\n",
        "        print(\"    ⚠ Relationship not statistically significant\")\n",
        "\n",
        "# Identify vulnerable hot spots\n",
        "print(\"\\n6.2 Identifying vulnerable hot spots...\")\n",
        "\n",
        "vulnerable_hotspots = demographic_data[\n",
        "    (demographic_data['vulnerability_index'] > demographic_data['vulnerability_index'].quantile(0.75))\n",
        "].copy()\n",
        "\n",
        "# Get temperatures for vulnerable areas\n",
        "vulnerable_temps = []\n",
        "for _, tract in vulnerable_hotspots.iterrows():\n",
        "    lon_idx = int((tract['lon'] - NYC_BOUNDS['west']) /\n",
        "                  (NYC_BOUNDS['east'] - NYC_BOUNDS['west']) * width)\n",
        "    lat_idx = int((NYC_BOUNDS['north'] - tract['lat']) /\n",
        "                  (NYC_BOUNDS['north'] - NYC_BOUNDS['south']) * height)\n",
        "\n",
        "    if 0 <= lon_idx < width and 0 <= lat_idx < height:\n",
        "        temp = risk_map[lat_idx, lon_idx]\n",
        "        if not np.isnan(temp):\n",
        "            vulnerable_temps.append(temp)\n",
        "\n",
        "if vulnerable_temps:\n",
        "    print(f\"    Vulnerable areas mean temperature: {np.mean(vulnerable_temps):.1f}°C\")\n",
        "    print(f\"    Overall mean temperature: {np.nanmean(risk_map):.1f}°C\")\n",
        "    print(f\"    Temperature difference: {np.mean(vulnerable_temps) - np.nanmean(risk_map):.1f}°C\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7: VISUALIZATIONS"
      ],
      "metadata": {
        "id": "KYXpFa4C5wSf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2jFyedJAqhF",
        "outputId": "1b01700c-0700-47c6-c3da-b0a170264ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 7: CREATING VISUALIZATIONS\n",
            "================================================================================\n",
            "    ✓ Saved: 01_temporal_prediction.png\n",
            "    ✓ Saved: 02_risk_map.png\n",
            "    ✓ Saved: 03_demographic_analysis.png\n",
            "    ✓ Saved: 04_executive_summary.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 7: CREATING VISUALIZATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Temporal Prediction Performance\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "for idx, (name, res) in enumerate(results.items()):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Scatter plot\n",
        "    ax.scatter(y_predict, res['predictions'], alpha=0.5, s=10, c=y_predict, cmap='coolwarm')\n",
        "\n",
        "    # Perfect prediction line\n",
        "    min_val = min(y_predict.min(), res['predictions'].min())\n",
        "    max_val = max(y_predict.max(), res['predictions'].max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "\n",
        "    # Metrics\n",
        "    ax.text(0.05, 0.95,\n",
        "            f\"R² = {res['r2']:.3f}\\nMAE = {res['mae']:.2f}°C\\nRMSE = {res['rmse']:.2f}°C\",\n",
        "            transform=ax.transAxes, va='top', fontsize=10,\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "    ax.set_xlabel('Actual 2025 Temperature (°C)')\n",
        "    ax.set_ylabel('Predicted 2025 Temperature (°C)')\n",
        "    ax.set_title(f'{name} - Temporal Prediction', fontweight='bold')\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Temporal Prediction: 2024 → 2025', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/01_temporal_prediction.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"    ✓ Saved: 01_temporal_prediction.png\")\n",
        "plt.close()\n",
        "\n",
        "# 2. High-Risk Area Map\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Temperature map\n",
        "ax1 = axes[0]\n",
        "im1 = ax1.imshow(risk_map, cmap='hot', aspect='auto')\n",
        "ax1.set_title('Predicted Temperature (2025)', fontweight='bold')\n",
        "ax1.axis('off')\n",
        "cbar1 = plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
        "cbar1.set_label('Temperature (°C)', rotation=270, labelpad=20)\n",
        "\n",
        "# High-risk areas\n",
        "ax2 = axes[1]\n",
        "risk_binary = np.where(risk_map > threshold, 1, 0)\n",
        "risk_binary_masked = np.ma.masked_where(risk_binary == 0, risk_binary)\n",
        "ax2.imshow(np.ones_like(risk_map) * 0.9, cmap='gray', aspect='auto')  # Background\n",
        "im2 = ax2.imshow(risk_binary_masked, cmap='Reds', aspect='auto', alpha=0.8)\n",
        "ax2.set_title(f'High-Risk Areas (>{threshold:.1f}°C)', fontweight='bold')\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.suptitle('Urban Heat Risk Mapping - NYC 2025', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/02_risk_map.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"    ✓ Saved: 02_risk_map.png\")\n",
        "plt.close()\n",
        "\n",
        "# 3. Demographic Vulnerability Analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "# Temperature vs Vulnerability\n",
        "ax1 = axes[0, 0]\n",
        "if tract_temperatures and tract_vulnerabilities:\n",
        "    ax1.scatter(tract_vulnerabilities, tract_temperatures, alpha=0.6, s=50, c=tract_temperatures, cmap='coolwarm')\n",
        "    z = np.polyfit(tract_vulnerabilities, tract_temperatures, 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax1.plot(tract_vulnerabilities, p(tract_vulnerabilities), \"r--\", alpha=0.8, lw=2)\n",
        "ax1.set_xlabel('Vulnerability Index')\n",
        "ax1.set_ylabel('Temperature (°C)')\n",
        "ax1.set_title('Temperature vs Social Vulnerability', fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Income vs Temperature\n",
        "ax2 = axes[0, 1]\n",
        "income_temps = []\n",
        "incomes = []\n",
        "for _, tract in demographic_data.iterrows():\n",
        "    lon_idx = int((tract['lon'] - NYC_BOUNDS['west']) /\n",
        "                  (NYC_BOUNDS['east'] - NYC_BOUNDS['west']) * width)\n",
        "    lat_idx = int((NYC_BOUNDS['north'] - tract['lat']) /\n",
        "                  (NYC_BOUNDS['north'] - NYC_BOUNDS['south']) * height)\n",
        "\n",
        "    if 0 <= lon_idx < width and 0 <= lat_idx < height:\n",
        "        temp = risk_map[lat_idx, lon_idx]\n",
        "        if not np.isnan(temp) and temp > 0:\n",
        "            income_temps.append(temp)\n",
        "            incomes.append(tract['median_income'])\n",
        "\n",
        "if income_temps:\n",
        "    ax2.scatter(incomes, income_temps, alpha=0.6, s=50, c=income_temps, cmap='coolwarm')\n",
        "ax2.set_xlabel('Median Income ($)')\n",
        "ax2.set_ylabel('Temperature (°C)')\n",
        "ax2.set_title('Income vs Temperature', fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# Vulnerability components\n",
        "ax3 = axes[1, 0]\n",
        "vuln_components = ['poverty_rate', 'elderly_pct', 'minority_pct', 'no_ac_pct']\n",
        "vuln_means = [demographic_data[col].mean() for col in vuln_components]\n",
        "colors = ['#E74C3C', '#3498DB', '#2ECC71', '#F39C12']\n",
        "bars = ax3.bar(range(len(vuln_components)), vuln_means, color=colors, alpha=0.7)\n",
        "ax3.set_xticks(range(len(vuln_components)))\n",
        "ax3.set_xticklabels(['Poverty\\nRate', 'Elderly\\n%', 'Minority\\n%', 'No AC\\n%'], rotation=0)\n",
        "ax3.set_ylabel('Percentage (%)')\n",
        "ax3.set_title('Vulnerability Components - NYC Average', fontweight='bold')\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Feature importance (from best model)\n",
        "ax4 = axes[1, 1]\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = best_model.feature_importances_\n",
        "    imp_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importances\n",
        "    }).sort_values('Importance', ascending=True).tail(6)\n",
        "\n",
        "    colors = plt.cm.viridis(imp_df['Importance'] / imp_df['Importance'].max())\n",
        "    ax4.barh(imp_df['Feature'], imp_df['Importance'], color=colors)\n",
        "    ax4.set_xlabel('Importance')\n",
        "    ax4.set_title('Top Features for Temperature Prediction', fontweight='bold')\n",
        "    ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.suptitle('Environmental Justice Analysis', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/03_demographic_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"    ✓ Saved: 03_demographic_analysis.png\")\n",
        "plt.close()\n",
        "\n",
        "# 4. Executive Summary Dashboard\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# Title\n",
        "fig.suptitle('NYC Urban Heat Vulnerability - Executive Summary', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Risk map (large)\n",
        "ax1 = fig.add_subplot(gs[0:2, 0:2])\n",
        "im = ax1.imshow(risk_map, cmap='hot', aspect='auto')\n",
        "ax1.set_title('Predicted Temperature Map (2025)')\n",
        "ax1.axis('off')\n",
        "plt.colorbar(im, ax=ax1, fraction=0.046, pad=0.04)\n",
        "\n",
        "# Key metrics\n",
        "ax2 = fig.add_subplot(gs[0, 2])\n",
        "ax2.axis('off')\n",
        "metrics_text = f\"\"\"\n",
        "KEY METRICS\n",
        "\n",
        "Model Performance:\n",
        "• R² Score: {results[best_model_name]['r2']:.3f}\n",
        "• MAE: {results[best_model_name]['mae']:.1f}°C\n",
        "• RMSE: {results[best_model_name]['rmse']:.1f}°C\n",
        "\n",
        "Temperature Stats:\n",
        "• Mean: {np.nanmean(risk_map):.1f}°C\n",
        "• Max: {np.nanmax(risk_map):.1f}°C\n",
        "• High-risk threshold: {threshold:.1f}°C\n",
        "\"\"\"\n",
        "ax2.text(0.1, 0.9, metrics_text, transform=ax2.transAxes, va='top', fontsize=11,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.3))\n",
        "\n",
        "# Vulnerability correlation\n",
        "ax3 = fig.add_subplot(gs[1, 2])\n",
        "if tract_temperatures and tract_vulnerabilities:\n",
        "    ax3.scatter(tract_vulnerabilities, tract_temperatures, alpha=0.5, s=20, c='#E74C3C')\n",
        "    z = np.polyfit(tract_vulnerabilities, tract_temperatures, 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax3.plot(tract_vulnerabilities, p(tract_vulnerabilities), \"r--\", alpha=0.8)\n",
        "ax3.set_xlabel('Vulnerability Index', fontsize=9)\n",
        "ax3.set_ylabel('Temperature (°C)', fontsize=9)\n",
        "ax3.set_title('Social Vulnerability', fontsize=10, fontweight='bold')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# Temporal change\n",
        "ax4 = fig.add_subplot(gs[2, 0])\n",
        "years = ['2024\\n(Training)', '2025\\n(Predicted)']\n",
        "temps = [np.nanmean(train_img[6]), np.nanmean(risk_map)]\n",
        "bars = ax4.bar(years, temps, color=['#3498DB', '#E74C3C'], alpha=0.7)\n",
        "ax4.set_ylabel('Mean Temperature (°C)')\n",
        "ax4.set_title('Temporal Change', fontsize=10, fontweight='bold')\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "for bar, temp in zip(bars, temps):\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "             f'{temp:.1f}°C', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Risk distribution\n",
        "ax5 = fig.add_subplot(gs[2, 1])\n",
        "temps_flat = risk_map[~np.isnan(risk_map)]\n",
        "ax5.hist(temps_flat, bins=30, color='#2ECC71', alpha=0.7, edgecolor='black')\n",
        "ax5.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'High-risk: {threshold:.1f}°C')\n",
        "ax5.set_xlabel('Temperature (°C)')\n",
        "ax5.set_ylabel('Pixel Count')\n",
        "ax5.set_title('Temperature Distribution', fontsize=10, fontweight='bold')\n",
        "ax5.legend()\n",
        "ax5.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Policy recommendations\n",
        "ax6 = fig.add_subplot(gs[2, 2])\n",
        "ax6.axis('off')\n",
        "recommendations = \"\"\"\n",
        "POLICY RECOMMENDATIONS\n",
        "\n",
        "1. Prioritize cooling centers in\n",
        "   high-vulnerability areas\n",
        "\n",
        "2. Increase tree canopy in\n",
        "   identified hotspots\n",
        "\n",
        "3. Target heat assistance to\n",
        "   low-income neighborhoods\n",
        "\n",
        "4. Implement cool roof programs\n",
        "   in high-risk zones\n",
        "\"\"\"\n",
        "ax6.text(0.1, 0.9, recommendations, transform=ax6.transAxes, va='top', fontsize=10,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
        "\n",
        "plt.savefig(f'{OUTPUT_DIR}/04_executive_summary.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"    ✓ Saved: 04_executive_summary.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQxc5M4KAqhG"
      },
      "source": [
        "# 8: CROSS-CITY GENERALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTGpAmTzAqhG",
        "outputId": "689c382b-1075-4065-c0b8-d4547ead239c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 8: CROSS-CITY GENERALIZATION POTENTIAL\n",
            "================================================================================\n",
            "\n",
            "8.1 Model generalization analysis...\n",
            "\n",
            "    Top predictive features (universal indicators):\n",
            "      • MNDWI: 0.561\n",
            "      • Brightness: 0.294\n",
            "      • UI: 0.120\n",
            "\n",
            "    Model characteristics for generalization:\n",
            "      • Uses spectral indices (universal)\n",
            "      • Temperature prediction R²: 0.841\n",
            "      • Expected transferability: MODERATE to HIGH\n",
            "\n",
            "    Recommended cities for testing:\n",
            "      • Similar climate: Boston, Philadelphia, Chicago\n",
            "      • Different climate: Phoenix, Miami, Los Angeles\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 8: CROSS-CITY GENERALIZATION POTENTIAL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n8.1 Model generalization analysis...\")\n",
        "\n",
        "# Feature importance analysis\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = best_model.feature_importances_\n",
        "\n",
        "    # Top features are universal urban indicators\n",
        "    top_features = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importances\n",
        "    }).sort_values('Importance', ascending=False).head(3)\n",
        "\n",
        "    print(\"\\n    Top predictive features (universal indicators):\")\n",
        "    for _, row in top_features.iterrows():\n",
        "        print(f\"      • {row['Feature']}: {row['Importance']:.3f}\")\n",
        "\n",
        "    print(\"\\n    Model characteristics for generalization:\")\n",
        "    print(f\"      • Uses spectral indices (universal)\")\n",
        "    print(f\"      • Temperature prediction R²: {results[best_model_name]['r2']:.3f}\")\n",
        "    print(f\"      • Expected transferability: MODERATE to HIGH\")\n",
        "\n",
        "    print(\"\\n    Recommended cities for testing:\")\n",
        "    print(\"      • Similar climate: Boston, Philadelphia, Chicago\")\n",
        "    print(\"      • Different climate: Phoenix, Miami, Los Angeles\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5: FINAL SUMMARY"
      ],
      "metadata": {
        "id": "iiJhY5Wh6Wsx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjxjaRc3AqhG",
        "outputId": "83b01bb4-98bf-482a-ec24-462d898bd9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "                    ANALYSIS COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "📊 TEMPORAL PREDICTION RESULTS:\n",
            "\n",
            "  🏆 Best Model: Gradient Boosting\n",
            "  📈 Temporal R²: 0.841\n",
            "  🎯 Temporal MAE: 2.19°C\n",
            "  📏 Temporal RMSE: 2.91°C\n",
            "\n",
            "🌡️ HIGH-RISK AREAS:\n",
            "  • Threshold: 42.7°C (top 20%)\n",
            "  • High-risk pixels: 69,474\n",
            "  • Percentage of city: 20.0%\n",
            "\n",
            "🏘️ ENVIRONMENTAL JUSTICE:\n",
            "  • Temperature-Vulnerability Correlation: -0.006\n",
            "  • Statistical significance: NO\n",
            "  • Vulnerable area temperature premium: -0.2°C\n",
            "\n",
            "🌍 GENERALIZATION POTENTIAL:\n",
            "  • Model uses universal urban indices\n",
            "  • Expected to work in similar climate cities\n",
            "  • Requires retraining for different climates\n",
            "\n",
            "📁 All outputs saved to: ./nyc_heat_vulnerability_output/\n",
            "  1. 01_temporal_prediction.png - 2024→2025 prediction performance\n",
            "  2. 02_risk_map.png - High-risk area identification\n",
            "  3. 03_demographic_analysis.png - Environmental justice analysis\n",
            "  4. 04_executive_summary.png - Executive dashboard\n",
            "\n",
            "💡 KEY INSIGHTS FOR PHD APPLICATION:\n",
            "  • Demonstrated temporal prediction capability\n",
            "  • Identified environmental justice implications\n",
            "  • Showed potential for cross-city generalization\n",
            "  • Combined remote sensing, ML, and social data\n",
            "\n",
            "================================================================================\n",
            "✨ Ready for your PhD applications! ✨\n",
            "🌆 Urban Heat Vulnerability Analysis Complete! 🔥\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" \" * 20 + \"ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "print(\"📊 TEMPORAL PREDICTION RESULTS:\\n\")\n",
        "print(f\"  🏆 Best Model: {best_model_name}\")\n",
        "print(f\"  📈 Temporal R²: {results[best_model_name]['r2']:.3f}\")\n",
        "print(f\"  🎯 Temporal MAE: {results[best_model_name]['mae']:.2f}°C\")\n",
        "print(f\"  📏 Temporal RMSE: {results[best_model_name]['rmse']:.2f}°C\")\n",
        "\n",
        "print(f\"\\n🌡️ HIGH-RISK AREAS:\")\n",
        "print(f\"  • Threshold: {threshold:.1f}°C (top 20%)\")\n",
        "print(f\"  • High-risk pixels: {high_risk_mask.sum():,}\")\n",
        "print(f\"  • Percentage of city: {high_risk_mask.mean()*100:.1f}%\")\n",
        "\n",
        "if correlation:\n",
        "    print(f\"\\n🏘️ ENVIRONMENTAL JUSTICE:\")\n",
        "    print(f\"  • Temperature-Vulnerability Correlation: {correlation:.3f}\")\n",
        "    print(f\"  • Statistical significance: {'YES' if p_value < 0.05 else 'NO'}\")\n",
        "    if vulnerable_temps:\n",
        "        print(f\"  • Vulnerable area temperature premium: {np.mean(vulnerable_temps) - np.nanmean(risk_map):.1f}°C\")\n",
        "\n",
        "print(f\"\\n🌍 GENERALIZATION POTENTIAL:\")\n",
        "print(f\"  • Model uses universal urban indices\")\n",
        "print(f\"  • Expected to work in similar climate cities\")\n",
        "print(f\"  • Requires retraining for different climates\")\n",
        "\n",
        "print(f\"\\n📁 All outputs saved to: {OUTPUT_DIR}/\")\n",
        "print(f\"  1. 01_temporal_prediction.png - 2024→2025 prediction performance\")\n",
        "print(f\"  2. 02_risk_map.png - High-risk area identification\")\n",
        "print(f\"  3. 03_demographic_analysis.png - Environmental justice analysis\")\n",
        "print(f\"  4. 04_executive_summary.png - Executive dashboard\")\n",
        "\n",
        "print(f\"\\n💡 KEY INSIGHTS FOR PHD APPLICATION:\")\n",
        "print(f\"  • Demonstrated temporal prediction capability\")\n",
        "print(f\"  • Identified environmental justice implications\")\n",
        "print(f\"  • Showed potential for cross-city generalization\")\n",
        "print(f\"  • Combined remote sensing, ML, and social data\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"✨ Ready for your PhD applications! ✨\")\n",
        "print(\"🌆 Urban Heat Vulnerability Analysis Complete! 🔥\")\n",
        "print(\"=\" * 80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWG_CeuAqhH"
      },
      "source": [
        "## MODEL 3 - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci85AzV9AqhH",
        "outputId": "ae88d29d-f6e1-455d-d11d-8b4dce0e2fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00     48363\n",
            "           1       1.00      0.95      0.98      5460\n",
            "\n",
            "    accuracy                           1.00     53823\n",
            "   macro avg       1.00      0.98      0.99     53823\n",
            "weighted avg       1.00      1.00      1.00     53823\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "svm.fit(X_train, y_train.ravel())\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "print(\"SVM Classifier:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1BwnbV_AqhH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}